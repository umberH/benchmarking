#!/usr/bin/env python3
"""
Integration script to add run organization to existing benchmark system
"""

from pathlib import Path
from run_organization_demo import create_run_structure

def integrate_with_main_py():
    """Show how to integrate run organization with main.py"""
    
    print("ğŸ”§ Integration with Main Benchmarking System")
    print("=" * 50)
    
    # Example integration code for main.py
    integration_code = '''
# Add to main.py before creating XAIBenchmark instance:

def setup_run_organization(args):
    """Setup run-based organization"""
    from run_organization_demo import create_run_structure
    
    # Determine run type based on arguments
    if args.comprehensive:
        run_type = "comprehensive"
    elif args.iterative:
        run_type = "iterative"
    else:
        run_type = "standard"
    
    # Create organized run structure
    run_info = create_run_structure(run_type=run_type)
    
    print(f"ğŸ“ Created run: {run_info['run_metadata']['run_name']}")
    print(f"ğŸ”— Latest run link: results/runs/latest")
    
    return run_info['paths']['run_dir']

# In main() function, replace:
# benchmark = XAIBenchmark(config, Path("results"))

# With:
# run_dir = setup_run_organization(args)
# benchmark = XAIBenchmark(config, run_dir)
'''
    
    print("ğŸ“ Integration Code:")
    print(integration_code)
    
    # Show benefits
    print("\nğŸ¯ Benefits for Users:")
    print("   âœ… Each run is completely isolated")
    print("   âœ… Easy to compare results across different experiments")
    print("   âœ… No overwriting of previous results")
    print("   âœ… Clean organization of models, logs, and reports")
    print("   âœ… Dashboard can now show multiple runs")
    print("   âœ… Complete audit trail of all experiments")
    
    # Show usage examples
    print("\nğŸ’¡ Usage Examples:")
    print("   python main.py --comprehensive")
    print("   â†’ Creates: results/runs/run_20250818_144500_comprehensive/")
    print("   ")
    print("   python main.py --iterative adult_income decision_tree shap")
    print("   â†’ Creates: results/runs/run_20250818_144600_iterative/")
    print("   ")
    print("   python main.py")
    print("   â†’ Creates: results/runs/run_20250818_144700_standard/")

def show_dashboard_integration():
    """Show how dashboard will work with run organization"""
    
    print("\nğŸ–¥ï¸ Dashboard Integration Benefits")
    print("=" * 40)
    
    print("ğŸ“Š Enhanced Dashboard Features:")
    print("   â€¢ Select specific runs from dropdown")
    print("   â€¢ Compare performance across multiple runs")
    print("   â€¢ View run metadata and experiment details")
    print("   â€¢ Track experiment evolution over time")
    print("   â€¢ Load run-specific detailed explanations")
    
    print("\nğŸ”„ Multi-Run Comparison:")
    print("   â€¢ Side-by-side performance analysis")
    print("   â€¢ Track method improvements over time")
    print("   â€¢ Identify best-performing configurations")
    print("   â€¢ Analyze consistency across runs")

def create_sample_runs():
    """Create sample runs to demonstrate the system"""
    
    print("\nğŸ§ª Creating Sample Runs for Testing")
    print("=" * 40)
    
    run_types = ["comprehensive", "targeted", "experimental"]
    
    for run_type in run_types:
        run_info = create_run_structure(run_type=run_type)
        print(f"âœ… Created sample {run_type} run: {run_info['run_metadata']['run_name']}")
    
    print(f"\nğŸ“ All runs stored in: results/runs/")
    print(f"ğŸ”— Latest run: results/runs/latest")

if __name__ == "__main__":
    integrate_with_main_py()
    show_dashboard_integration()
    
    # Ask user if they want to create sample runs
    response = input("\nâ“ Create sample runs for testing? (y/n): ").lower().strip()
    if response == 'y':
        create_sample_runs()
        print("\nğŸ‰ Sample runs created! You can now test the dashboard with multiple runs.")
    
    print(f"\nğŸš€ Next Steps:")
    print(f"   1. Integrate run organization into main.py")
    print(f"   2. Test comprehensive benchmarking with new structure")
    print(f"   3. Use dashboard to compare multiple runs")
    print(f"   4. Enjoy organized, professional experiment management!")